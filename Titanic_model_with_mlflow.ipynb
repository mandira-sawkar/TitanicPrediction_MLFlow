{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e7aebfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score, confusion_matrix\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow import log_metric, log_param, log_artifacts\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "04ef9ad7-2191-4820-a66f-4a529cb7a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign values to columns and get dummies\n",
    "def imputation(df, col_name):\n",
    "    col = df[col_name].unique()\n",
    "    i=0\n",
    "    coldict = {}\n",
    "    for c in col:\n",
    "        coldict[c] = i\n",
    "        i=i+1\n",
    "    df.replace({col_name:coldict},inplace=True)\n",
    "    df = pd.get_dummies(df, columns=[col_name])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ea01cf21-33e9-485d-9c57-bae0ad8e1817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_analysis():\n",
    "#     titanic_attr = titanic_df.iloc[:, 0:10]\n",
    "#     sns.pairplot(titanic_attr, diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f7505aa6-c73f-459b-8677-8dafba76c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    train, test = train_test_split(titanic_df, test_size=0.20, random_state=1)\n",
    "\n",
    "    X_train = train.drop(\"Survived\",axis=1)\n",
    "    y_train = train[\"Survived\"]\n",
    "    X_test = test.drop(\"PassengerId\",axis=1).copy()\n",
    "    y_test = test[\"Survived\"]\n",
    "    X_train.shape, y_train.shape, X_test.shape\n",
    "    mlflow.log_param(\"Train shape\",X_train.shape )\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d9f0f6a3-ace9-4609-8dd7-c0fda8c9b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train with Gaussian Naive Bayes\n",
    "def gaussian_nb(X_train, y_train, X_test, y_test):\n",
    "    gaussian_nb = GaussianNB()\n",
    "    gaussian_nb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = gaussian_nb.predict(X_test)\n",
    "\n",
    "    gnb_score = gaussian_nb.score(X_train, y_train)\n",
    "    mlflow.log_metric(\"Accuracy for this run\", gnb_score)\n",
    "    # mlflow.log_metric(\"Precision for this run\", precision_score(y_test, y_pred, average=None))\n",
    "    # mlflow.log_metric(\"Recall for this run\", recall_score(y_test, y_pred, average=None))\n",
    "    # mlflow.log_metric(\"f1 for this run\", f1_score(y_test, y_pred, average=None))\n",
    "    \n",
    "    mlflow.sklearn.log_model(gaussian_nb, \"Gaussian Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ffb0b24b-d6ac-4eb5-b9f9-a42837daf38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train with Logistic Regression\n",
    "def logistic_reg(X_train, y_train, X_test, y_test):\n",
    "    logistic_reg = LogisticRegression()\n",
    "    logistic_reg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = logistic_reg.predict(X_test)\n",
    "\n",
    "    lr_score = logistic_reg.score(X_train, y_train)\n",
    "    mlflow.log_metric(\"Accuracy for this run\", lr_score)\n",
    "    # mlflow.log_metric(\"Precision for this run\", precision_score(y_test, y_pred, average=None))\n",
    "    # mlflow.log_metric(\"Recall for this run\", recall_score(y_test, y_pred, average=None))\n",
    "    # mlflow.log_metric(\"f1 for this run\", f1_score(y_test, y_pred, average=None))\n",
    "    \n",
    "    mlflow.sklearn.log_model(logistic_reg, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "82dd9f1e-e3a5-490b-a99f-85e212780935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train with KNeighbours Classifier\n",
    "def knn(X_train, y_train, X_test, y_test, neigb):\n",
    "    knn = KNeighborsClassifier(n_neighbors = neigb)\n",
    "    mlflow.log_param(\"n_neighbors\", neigb)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    knn_score = knn.score(X_train, y_train)\n",
    "    mlflow.log_metric(\"Accuracy for this run\", knn_score)\n",
    "    # mlflow.log_metric(\"Precision for this run\", precision_score(y_test, y_pred, average=None))\n",
    "    # mlflow.log_metric(\"Recall for this run\", recall_score(y_test, y_pred, average=None))\n",
    "    # mlflow.log_metric(\"f1 for this run\", f1_score(y_test, y_pred, average=None))\n",
    "    \n",
    "    mlflow.sklearn.log_model(knn, \"KNeighbours Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1b23eb0e-433d-4c92-b6e8-b573fca934ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train with Random Forest\n",
    "def random_forest(X_train, y_train, X_test, y_test, n_est, max_dep, crit=\"gini\"):\n",
    "    random_forest = RandomForestClassifier(n_estimators=n_est, criterion=crit, max_depth=max_dep)\n",
    "    mlflow.log_param(\"n_estimators\", n_est)\n",
    "    # mlflow.log_param(\"criterion\", crit)\n",
    "    # mlflow.log_param(\"max_depth\", max_dep)\n",
    "    random_forest.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = random_forest.predict(X_test)\n",
    "\n",
    "    rf_score = random_forest.score(X_train, y_train)\n",
    "    mlflow.log_metric(\"Accuracy for this run\", rf_score)\n",
    "    # mlflow.log_metric(\"Precision for this run\", precision_score(y_test, y_pred, average=None))\n",
    "    # mlflow.log_metric(\"Recall for this run\", recall_score(y_test, y_pred, average=None))\n",
    "    # mlflow.log_metric(\"f1 for this run\", f1_score(y_test, y_pred, average=None))\n",
    "    \n",
    "    mlflow.sklearn.log_model(random_forest, \"Random Forest Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023ee55-6382-4504-bb22-f6671295cd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "85cc3a42-631f-40f7-92b8-9f317e98f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the experiments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda_tmp\\ipykernel_8380\\2772344948.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  titanic_df['Family'].loc[titanic_df['Family'] > 0] = 1\n",
      "C:\\conda_tmp\\ipykernel_8380\\2772344948.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  titanic_df['Family'].loc[titanic_df['Family'] == 0] = 0\n",
      "C:\\Users\\raveendra sawkar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Survived\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- PassengerId\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\raveendra sawkar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\raveendra sawkar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Survived\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- PassengerId\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\raveendra sawkar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Survived\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- PassengerId\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\raveendra sawkar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Survived\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- PassengerId\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('Starting the experiments')\n",
    "\n",
    "    ##mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(experiment_name='Titanic')\n",
    "    titanic_df = pd.read_csv('Titanic+Data+Set.csv')\n",
    "    mlflow.log_artifact(\"Titanic+Data+Set.csv\")\n",
    "\n",
    "    # Check for null vals and drop unnecessary cols\n",
    "    titanic_df.isnull().sum()\n",
    "    titanic_df = titanic_df.drop(\"Cabin\", axis=1)\n",
    "    titanic_df = titanic_df.drop(\"Name\", axis=1)\n",
    "    titanic_df = titanic_df.drop(\"Ticket\", axis=1)\n",
    "\n",
    "    # Fill null vals\n",
    "    titanic_df['Embarked'].describe()\n",
    "    titanic_df['Embarked'] = titanic_df['Embarked'].fillna('S')\n",
    "    titanic_df.isnull().sum()\n",
    "    titanic_df['Age'].describe()\n",
    "    titanic_df['Age'] = titanic_df['Age'].fillna(28)\n",
    "    titanic_df.isnull().sum()\n",
    "    titanic_df.dtypes\n",
    "\n",
    "    # Create family feature from Parch & SibSp\n",
    "    titanic_df['Family'] = titanic_df[\"Parch\"] + titanic_df[\"SibSp\"]\n",
    "    titanic_df['Family'].loc[titanic_df['Family'] > 0] = 1\n",
    "    titanic_df['Family'].loc[titanic_df['Family'] == 0] = 0\n",
    "    # drop Parch & SibSp\n",
    "    titanic_df = titanic_df.drop(['SibSp', 'Parch'], axis=1)\n",
    "\n",
    "    # Separate columns\n",
    "    titanic_df = imputation(titanic_df, 'Sex')\n",
    "    titanic_df = imputation(titanic_df, 'Embarked')\n",
    "    titanic_df = pd.get_dummies(titanic_df, columns=['Pclass', 'Family'])\n",
    "    titanic_df.dtypes\n",
    "\n",
    "    # Plot features and analyze\n",
    "    # plot_analysis()\n",
    "\n",
    "    X_train, y_train, X_test, y_test = split_data()\n",
    "    gaussian_nb(X_train, y_train, X_test, y_test)\n",
    "    logistic_reg(X_train, y_train, X_test, y_test)\n",
    "    knn(X_train, y_train, X_test, y_test, 3)\n",
    "    # knn(X_train, y_train, X_test, y_test, 6)\n",
    "    random_forest(X_train, y_train, X_test, y_test, 100, 8, \"gini\")\n",
    "    # random_forest(X_train, y_train, X_test, y_test, 50, 4, \"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7f8f3f6f-2371-46c9-b90e-e716869200d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3574192917.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [157], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    mlflow ui\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0149f17-a389-4d34-a58e-b871b5e9d3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
